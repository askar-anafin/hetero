## Контрольные вопросы

1. **В чём отличие стека и очереди?**
   - **Стек (Stack)**: Работает по принципу LIFO (Last In, First Out — последним пришёл, первым ушёл). Элементы добавляются и удаляются с одного конца (вершины).
   - **Очередь (Queue)**: Работает по принципу FIFO (First In, First Out — первым пришёл, первым ушёл). Элементы добавляются в конец (хвост) и удаляются из начала (головы).

2. **Какие проблемы возникают при параллельном доступе к данным?**
   - **Состояние гонки (Race Condition)**: Несколько потоков одновременно пытаются читать и записывать одну и ту же ячейку памяти, что приводит к непредсказуемым результатам.
   - **Когерентность данных**: Необходимость обеспечения видимости изменений, сделанных одним потоком, для других потоков.
   - **Блокировки и ожидания**: Потеря производительности из-за необходимости синхронизации доступа к общим ресурсам.

3. **Как атомарные операции помогают избежать конфликтов в параллельных структурах данных?**
   - Атомарные операции (например, `atomicAdd`, `atomicExch`, `atomicCAS`) выполняются как единое, неделимое действие. Никакой другой поток не может прервать атомарную операцию или увидеть промежуточное состояние памяти. Это гарантирует корректное обновление общих индексов (например, вершины стека или указателей очереди) без использования тяжелых мьютексов.

4. **Какие типы памяти CUDA используются для хранения данных?**
   - **Global Memory**: Самая большая, доступна всем потокам, но медленная (высокая задержка).
   - **Shared Memory**: Быстрая память внутри мультипроцессора (SM), общая для потоков одного блока. Используется для обмена данными между потоками.
   - **Registers**: Самая быстрая память, индивидуальная для каждого потока (локальные переменные).
   - **Local Memory**: Размещается в глобальной памяти, используется, когда не хватает регистров.
   - **Constant/Texture Memory**: Специализированные кэшируемые виды памяти для чтения (константы, текстуры).

5. **Как синхронизация потоков влияет на производительность?**
    - Синхронизация (например, `__syncthreads()`) заставляет потоки ждать, пока все потоки в блоке не достигнут точки синхронизации.
    - **Негативное влияние**: Простой потоков, которые достигли барьера раньше других (divergence), снижает общую эффективность вычислений. Чрезмерная синхронизация убивает параллелизм.
    - **Необходимость**: Без синхронизации невозможно гарантировать корректность алгоритмов, где потоки обмениваются данными (например, через shared memory).

6. **Почему разделяемая память важна для оптимизации работы параллельных структур данных?**
   - **Низкая задержка**: Доступ к shared memory в сотни раз быстрее, чем к global memory.
   - **Снижение нагрузки на шину памяти**: Использование shared memory позволяет объединять запросы к глобальной памяти (coalsceing) или вообще избегать лишних обращений к ней.
   - **Обмен данными**: Эффективный способ коммуникации между потоками внутри одного блока, что критично для реализации блочных сортировок, сканирования (scan) и редукции.
