# Практическая работа 2: Параллельные алгоритмы сортировки

Данный файл содержит ответы на контрольные вопросы по второй практической работе, посвященной реализации и анализу последовательных и параллельных алгоритмов сортировки (пузырьком, выбором и вставкой) с использованием OpenMP.

## Контрольные вопросы

### 1. В чём основные отличия алгоритмов сортировки пузырьком, выбором и вставкой?

* **Сортировка пузырьком (Bubble Sort):** Проходит по массиву многократно, сравнивая и обменивая соседние элементы, если они стоят в неправильном порядке. "Легкие" элементы "всплывают" наверх (или тяжелые тонут). Это один из самых простых, но и самых медленных алгоритмов ($O(n^2)$), совершающий много обменов.
* **Сортировка выбором (Selection Sort):** На каждом шаге ищет минимальный (или максимальный) элемент в неотсортированной части массива и меняет его местами с первым неотсортированным элементом. Делает меньше обменов, чем пузырьковая ($O(n)$ обменов), но количество сравнений всё равно $O(n^2)$.
* **Сортировка вставкой (Insertion Sort):** Строит отсортированный массив по одному элементу. Берет следующий элемент и "вставляет" его на правильное место в уже отсортированной части, сдвигая остальные элементы. Эффективна на почти отсортированных данных ($O(n)$) и небольших массивах, но в худшем случае также $O(n^2)$.

### 2. Почему параллельная реализация сортировки вставкой сложнее для выполнения с использованием OpenMP?

Параллелизация сортировки вставкой с помощью простых директив `omp for` затруднена из-за **сильной зависимости по данным (loop-carried dependency)**. Внутренний цикл (сдвиг элементов) зависит от результата предыдущих итераций внешнего цикла (состояние отсортированной части массива). Классический алгоритм строго последователен: нельзя корректно вставить $i$-й элемент, пока не вставлены все элементы до него ($0...i-1$). Для параллелизации требуются более сложные подходы (например, Shell sort или параллельное слияние), которые меняют структуру алгоритма.

### 3. Какие директивы OpenMP были использованы для параллельной реализации алгоритмов?

В коде (`sorters.h`) использовались следующие директивы и конструкции OpenMP:

* `#pragma omp parallel` — создание параллельного региона (группы потоков).
* `#pragma omp for` — распределение итераций цикла между потоками.
* `#pragma omp single` — выполнение блока кода только одним потоком (с неявной барьерной синхронизацией).
* `#pragma omp barrier` — явная барьерная синхронизация всех потоков.
* `#pragma omp atomic write` — атомарная запись в общую переменную (для флага `swapped`).
* `#pragma omp critical` — критическая секция для безопасного обновления разделяемых переменных (глобального минимума в Selection Sort).
* `nowait` (в `#pragma omp for nowait`) — отмена неявного барьера в конце цикла.

### 4. Какие преимущества и недостатки параллельной реализации алгоритмов сортировки на CPU?

**Преимущества:**

* **Ускорение работы (Speedup):** Значительное сокращение времени выполнения на больших массивах данных за счет использования всех ядер процессора.
* **Эффективность ресурсов:** Утилизация простаивающих мощностей multicore CPU.

**Недостатки:**

* **Накладные расходы (Overhead):** Создание потоков, управление ими и синхронизация (барьеры, критические секции) занимают время.
* **Сложность реализации:** Необходимо учитывать гонки данных (data races), обеспечивать правильную синхронизацию переменных.
* **Ограничения масштабируемости:** Закон Амдала ограничивает максимальное ускорение последовательной частью алгоритма. Некоторые алгоритмы (как Bubble Sort) плохо масштабируются из-за частых синхронизаций.
* **Пропускная способность памяти:** Сортировка — задача, интенсивная по работе с памятью. Множество потоков могут упереться в пропускную способность шины памяти (Memory Wall).

### 5. Как можно измерить производительность программы в C++?

Для измерения времени выполнения можно использовать:

1. **OpenMP API:** Функция `omp_get_wtime()`, которая возвращает время в секундах (double) с высокой точностью. Это наиболее удобный способ для OpenMP программ.
2. **C++ Standard Library:** Библиотека `<chrono>` (например, `std::chrono::high_resolution_clock`).
3. **Профилировщики:** Внешние инструменты (gprof, Valgrind, Intel VTune) для детального анализа времени, кэш-промахов и использования CPU.

### 6. Как изменяется производительность сортировок при увеличении числа потоков?

При увеличении числа потоков производительность (время выполнения) обычно меняется следующим образом:

1. **Рост:** Сначала время выполнения уменьшается пропорционально числу ядер (линейное или близкое к нему ускорение).
2. **Насыщение:** При приближении к количеству физических ядер ускорение замедляется.
3. **Деградация:** Если число потоков значительно превышает число физических ядер, производительность может упасть из-за накладных расходов планировщика ОС на переключение контекста (context switching) и конкуренции за кэш/память (false sharing, cache thrashing).
Для малых массивов добавление потоков сразу ухудшает производительность.

### 7. В каких ситуациях параллельная сортировка может быть менее эффективной, чем последовательная?

* **Малый размер данных:** Накладные расходы на создание и синхронизацию потоков превышают выигрыш от параллельных вычислений. Сортировка массива из 100 элементов быстрее одним потоком.
* **Алгоритмические особенности:** Если алгоритм требует частой синхронизации (как примитивный параллельный Bubble Sort) или имеет "тяжелые" критические секции.
* **Ограничение памяти:** Если задача упирается в скорость доступа к памяти, добавление потоков только усилит конкуренцию за шину, не ускоряя вычисления.
* **Высокая загрузка системы:** Если CPU уже занят другими задачами, лишние потоки создадут конкуренцию за ресурсы.
