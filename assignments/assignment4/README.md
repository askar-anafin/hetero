# Контрольные вопросы к Assignment 4

1. **В чём заключается отличие гибридных вычислений от вычислений только на CPU или только на GPU?**
   Гибридные вычисления используют сильные стороны обеих архитектур одновременно: CPU отвечает за управление, последовательную логику и сложные ветвления, а GPU берет на себя массово-параллельные вычисления. В однородных вычислениях (только CPU или только GPU) потенциал второй архитектуры простаивает, что снижает общую эффективность.

2. **Для каких типов задач целесообразно распределять вычисления между CPU и GPU?**
   Это целесообразно для ресурсоемких задач, которые можно разделить на сложную логику управления (CPU) и параллельную обработку огромных массивов данных (GPU). Примеры: физическое моделирование, обучение нейронных сетей, криптография, рендеринг сложной графики.

3. **В чём разница между синхронной и асинхронной передачей данных между CPU и GPU?**
   Синхронная передача блокирует поток выполнения CPU до тех пор, пока данные не будут полностью скопированы. Асинхронная передача позволяет CPU продолжать выполнение других инструкций (например, вычисления или запуск ядер GPU) параллельно с процессом копирования данных.

4. **Почему асинхронная передача данных может повысить производительность программы?**
   Она позволяет "скрыть" задержки передачи данных (latency hiding) за счет перекрытия (overlap) вычислений и коммуникаций. Пока данные передаются по шине PCIe, GPU может обрабатывать уже имеющиеся данные, а CPU — готовить следующую порцию.

5. **Какие основные функции MPI используются для распределения и сбора данных между процессами?**
   - `MPI_Scatter` — распределение частей массива от одного процесса всем остальным.
   - `MPI_Gather` — сбор частей массива от всех процессов в один.
   - `MPI_Bcast` — рассылка одного и того же блока данных всем процессам.
   - `MPI_Reduce` — сбор данных с выполнением математической операции (например, суммы).
   - `MPI_Send` / `MPI_Recv` — точечная передача данных между двумя конкретными процессами.

6. **Как количество процессов MPI влияет на время выполнения программы и почему?**
   Увеличение числа процессов обычно сокращает время выполнения (ускорение), так как работа делится на большее число исполнителей. Однако при чрезмерном росте числа процессов накладные расходы на коммуникации между процессами (MPI overhead) начинают превышать выигрыш от распараллеливания, и время работы может снова начать расти.

7. **Какие факторы ограничивают масштабируемость распределённых параллельных программ?**
   - Задержки в сети передачи данных.
   - Несбалансированная нагрузка (одни процессы ждут другие).
   - Наличие строго последовательных участков кода (закон Амдала).
   - Ограниченная пропускная способность памяти и сетевых интерфейсов.

8. **В каких случаях использование распределённых вычислений оправдано, а в каких — неэффективно?**
   - **Оправдано:** когда задача не помещается в память одного узла или требует вычислительных мощностей, значительно превосходящих возможности одной машины.
   - **Неэффективно:** для задач с малым объемом вычислений, где время на инициализацию MPI и передачу данных по сети значительно превышает время выполнения самой задачи.
