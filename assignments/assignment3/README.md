# Контрольные вопросы к Assignment 3

### 1. Какие основные типы памяти существуют в архитектуре CUDA и чем они отличаются по скорости доступа?

В архитектуре CUDA существуют следующие основные типы памяти:

* **Регистры (Registers):** Самая быстрая память, расположенная непосредственно на чипе. Доступ к ней осуществляется за минимальное количество тактов. Индивидуальна для каждого потока.
* **Разделяемая память (Shared Memory):** Быстрая память на чипе, общая для всех потоков внутри одного блока. Значительно быстрее глобальной памяти, но медленнее регистров. Предназначена для межпоточного взаимодействия и кэширования данных.
* **Глобальная память (Global Memory):** Самая большая по объему, но самая медленная память (находится вне чипа, в видеопамяти DRAM). Доступна всем потокам во всех блоках и сетках.
* **Локальная память (Local Memory):** Расположена в той же области, что и глобальная память (DRAM), поэтому имеет такую же низкую скорость. Используется для хранения данных потока, которые не поместились в регистры (например, большие массивы или при переполнении стека).
* **Константная (Constant Memory) и Текстурная (Texture Memory):** Специализированные типы памяти, расположенные в DRAM, но кэшируемые на чипе. Быстры при определенных шаблонах доступа (например, одновременное чтение одного адреса всеми потоками варпа для константной памяти).

### 2. В каких случаях использование разделяемой памяти позволяет ускорить выполнение CUDA-программы?

Использование разделяемой памяти (Shared Memory) выгодно в следующих случаях:

* **Повторное использование данных:** Когда несколько потоков в блоке должны многократно обращаться к одним и тем же данным из глобальной памяти. Данные загружаются один раз в shared memory, и последующие обращения происходят на порядок быстрее.
* **Смена шаблона доступа (Memory Coalescing):** Когда потоки обращаются к глобальной памяти хаотично. Можно загрузить данные в shared memory согласованно (coalesced), а затем обрабатывать их в любом порядке внутри блока.
* **Межпоточное взаимодействие:** Для обмена данными между потоками одного блока (например, при реализации алгоритмов редукции или префиксных сумм).

### 3. Как шаблон доступа к глобальной памяти влияет на производительность GPU-программы?

Шаблон доступа критически важен из-за механизма **объединения транзакций (Memory Coalescing)**.

* Если потоки одного варпа (32 потока) обращаются к идущим подряд ячейкам памяти (например, `array[threadIdx.x]`), контроллер памяти может объединить эти запросы в одну или несколько транзакций. Это максимизирует пропускную способность.
* Если доступ «разбросан» (несогласован), контроллер вынужден выполнять множество отдельных транзакций, что приводит к простою вычислительных ядер (latency) и низкой эффективности использования шины памяти.

### 4. Почему одинаковый алгоритм на GPU может показывать разное время выполнения при разных способах обращения к памяти?

Разница обусловлена иерархией памяти и аппаратными особенностями GPU:

* **Пропускная способность (Bandwidth):** Доступ к регистрам и shared memory имеет колоссально большую пропускную способность по сравнению с глобальной памятью.
* **Задержки (Latency):** Обращение к глобальной памяти занимает сотни тактов, в то время как к shared memory — единицы тактов. Если алгоритм не скрывает задержки (мало потоков) или плохо работает с кэшем/объединением транзакций, время выполнения сильно возрастает.
* **Конфликты банков (Bank Conflicts):** В разделяемой памяти при неудачном обращении (несколько потоков к разным адресам одного банка) запросы выстраиваются в очередь, что замедляет работу.

### 5. Как размер блока потоков влияет на производительность CUDA-ядра?

Размер блока влияет на **Occupancy (коэффициент заполнения)** GPU:

* **Слишком маленькие блоки:** Не позволяют полностью загрузить мультипроцессоры (SM) и скрыть задержки доступа к памяти.
* **Слишком большие блоки:** Могут потреблять слишком много ресурсов SM (регистров или shared memory), что ограничит количество блоков, которые могут выполняться на одном SM одновременно.
* Обычно рекомендуется выбирать размер блока кратным 32 (размеру варпа), чаще всего 128, 256 или 512 потоков.

### 6. Что такое варп и почему важно учитывать его при разработке CUDA-программ?

**Варп (Warp)** — это базовая единица исполнения в архитектуре NVIDIA, состоящая из 32 потоков.

* Потоки внутри варпа выполняются по принципу **SIMT** (Single Instruction, Multiple Threads) — одновременно выполняют одну и ту же инструкцию.
* **Важность:** Если внутри варпа возникает ветвление (`if-else`), где часть потоков идет по одной ветке, а часть по другой, происходит **дивергенция варпа (Warp Divergence)**. В этом случае ветки выполняются последовательно, что снижает производительность.

### 7. Какие факторы необходимо учитывать при выборе конфигурации сетки и блоков потоков?

При выборе конфигурации `(gridDim, blockDim)` учитываются:

* **Количество ядер и SM на GPU:** Сетка должна быть достаточно большой, чтобы загрузить все доступные аппаратные ресурсы.
* **Ресурсные ограничения:** Объем shared memory и количество регистров на блок.
* **Размер данных:** Общее количество потоков должно быть не меньше количества элементов данных для обработки.
* **Кратность 32:** `blockDim` должен быть кратен размеру варпа для эффективного исполнения.

### 8. Почему оптимизация CUDA-программы часто начинается с анализа работы с памятью, а не с изменения алгоритма?

Потому что в большинстве задач на GPU узким местом (bottleneck) является именно **память (Memory-Bound задачи)**, а не вычислительная мощность.

* Арифметические операции выполняются во много раз быстрее, чем происходит доставка данных из глобальной памяти.
* Даже самый эффективный алгоритм будет работать медленно, если данные поставляются неэффективно (без coalescing или через медленную глобальную память там, где можно использовать shared). Оптимизация доступа к памяти часто дает кратный прирост производительности, который невозможно получить просто «улучшая формулы».
