# Практическая работа 7: Отчет

## 1. Теоретическая часть

### Редукция

Редукция — это алгоритм, который уменьшает массив данных до одного значения, применяя ассоциативный бинарный оператор (например, сумма, минимум, максимум). На GPU редукция реализуется параллельно, обычно используя древовидную структуру (логарифмическая сложность шагов).
В данной работе реализована **сумма элементов массива**.

### Сканирование (Префиксная сумма)

Сканирование (Prefix Sum) преобразует массив $[a_0, a_1, \dots, a_n]$ в $[a_0, a_0+a_1, \dots, \sum a_i]$.
Алгоритм является ключевым примитивом для параллельных сортировок (Radix Sort), фильтрации данных (Stream Compaction) и построения структур данных.
Существует два основных подхода:

1. **Hillis-Steele**: Простой для реализации (Step-efficient), но выполняет $O(N \log N)$ сложений (менее эффективен по работе).
2. **Blelloch**: Эффективный по работе ($O(N)$ сложений), состоящий из двух фаз (Up-Sweep и Down-Sweep).

### Типы памяти CUDA

* **Глобальная память**: Медленная, доступна всем. Используется для хранения входных и выходных данных.
* **Разделяемая память (Shared Memory)**: Быстрая (на кристалле), доступна потокам одного блока. Критически важна для эффективной редукции и сканирования внутри блока, позволяя избежать лишних обращений в глобальную память.

## 2. Практическая часть

### Реализация

1. **Редукция (`reduce_shared`)**:
    * Использует разделяемую память для загрузки блока данных.
    * Выполняет древовидную редукцию внутри блока в shared memory.
    * Частичные суммы блоков записываются в глобальную память.
    * Финальное суммирование частичных сумм выполняется на CPU (так как их количество мало, например, для 10 млн элементов это ~39 тыс. значений, что быстрее сложить на CPU, чем запускать новое ядро и копировать).

2. **Сканирование (`scan_block_kernel` + Рекурсия)**:
    * **Внутри блока**: Используется алгоритм Hillis-Steele в разделяемой памяти.
    * **Между блоками**: Используется рекурсивный подход (похожий на Blelloch "Scan-then-Fan"):
        1. Вычисляются суммы блоков.
        2. Рекурсивно сканируется массив сумм блоков.
        3. Результат добавляется ко всем элементам соответствующих блоков (`add_block_sum`).

### Исходный код

Код представлен в файлах:

* `kernels.cuh`: Реализация GPU ядер.
* `main.cu`: Хост-код, управление памятью и замеры времени.

## 3. Результаты и Анализ производительности

Тестирование проводилось на видеокарте NVIDIA (RTX3060).
Размер блока: 256 потоков.

### Таблица производительности (Время в мс)

| Размер массива (N) | Редукция GPU | Редукция CPU | Ускорение (x) | Сканирование GPU | Сканирование CPU | Ускорение (x) |
|--------------------|--------------|--------------|---------------|------------------|------------------|---------------|
| **1 024**          | 0.43 мс      | 0.009 мс     | 0.02x (Медленнее)| 0.17 мс          | 0.014 мс         | 0.08x         |
| **1 000 000**      | 0.13 мс      | 1.31 мс      | **10.4x**     | 1.05 мс          | 7.35 мс          | **7.0x**      |
| **10 000 000**     | 1.01 мс      | 13.24 мс     | **13.1x**     | 1.84 мс          | 78.67 мс         | **42.8x**     |

### Графический анализ (ASCII)

```text
Время выполнения (мс) для N = 10 000 000 (Меньше - лучше)

Редукция:
CPU: [#############] 13.24
GPU: [#] 1.01

Сканирование:
CPU: [########################################] 78.67
GPU: [#] 1.84
```

### Выводы

1. **Малые массивы (1К)**: Использование GPU нецелесообразно из-за накладных расходов на запуск ядер и копирование данных (overhead). CPU работает значительно быстрее.
2. **Большие массивы (1М - 10М)**: GPU показывает значительное превосходство.
    * Для **Редукции** ускорение достигает **13x**. Лимитирующим фактором для GPU является пропускная способность памяти (Memory Bound), так как арифметическая интенсивность редукции очень низкая.
    * Для **Сканирования** ускорение достигает **42x**. Это отличный результат, показывающий эффективность использования иерархии памяти и рекурсивного алгоритма, который распараллеливает зависимые вычисления.
3. **Оптимизация**:
    * Использование **Shared Memory** позволило сократить количество обращений к глобальной памяти в `blockDim.x` раз на этапе внутриблочной обработки.
    * Векторизованные загрузки (int4) могли бы еще больше ускорить работу (не реализовано в базовой версии).

### Дополнительные задания

* Реализована эффективная версия сканирования (схожая с Blelloch по структуре Scan-Add).
* Алгоритм легко адаптируется для нахождения минимума/максимума заменой операции `+` на `max()`/`min()` в ядре редукции.
