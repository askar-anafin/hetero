# Практика 9. Контрольные вопросы

## 1. Как изменяется время выполнения программы при увеличении количества процессов? Почему?

При увеличении количества процессов время выполнения параллельной части программы, как правило, **уменьшается**, поскольку общий объем вычислительной работы распределяется между большим числом исполнителей.

**Почему это происходит:**

* **Параллелизм:** Каждому процессу достается меньшая доля данных или итераций цикла для обработки.
* **Закон Амдала:** Однако, ускорение ограничено долей последовательного кода, который нельзя распараллелить.
* **Накладные расходы:** При чрезмерном увеличении числа процессов время может перестать уменьшаться или даже начать **расти**. Это связано с тем, что накладные расходы на создание процессов, синхронизацию и передачу данных (коммуникацию) начинают превышать выигрыш от параллельных вычислений.

## 2. Какие факторы могут влиять на производительность программы?

На производительность параллельной программы влияют множество факторов, включая:

* **Архитектура оборудования:** Производительность процессоров (CPU), объем и скорость оперативной памяти, пропускная способность и задержка (latency) сети (интерконнекта).
* **Балансировка нагрузки (Load Balancing):** Если одни процессы выполняют больше работы, чем другие, общая производительность будет ограничена самым медленным процессом.
* **Коммуникационные расходы:** Частота и объем передаваемых данных между процессами. Высокая латентность сети может существенно замедлить работу.
* **Эффективность алгоритма:** Сложность вычислений и возможность эффективного распараллеливания.
* **Синхронизация:** Частое ожидание на барьерах или блокировках снижает эффективность.
* **Кэш-память:** Эффективность использования кэша процессора (локальность данных).

## 3. Как можно оптимизировать передачу данных между процессами?

Для оптимизации обмена данными можно применять следующие стратегии:

* **Минимизация количества сообщений:** Объединение множества мелких сообщений в одно крупное для снижения накладных расходов на инициализацию передачи (latency).
* **Использование асинхронных операций:** Использование неблокирующих вызовов (`MPI_Isend`, `MPI_Irecv`), чтобы процессы могли выполнять полезные вычисления во время передачи данных (перекрытие вычислений и коммуникаций).
* **Коллективные операции:** Использование оптимизированных коллективных операций (`MPI_Bcast`, `MPI_Scatter`, `MPI_Reduce`) вместо реализации их через множество операций точка-точка.
* **Оптимизация топологии:** Учет физической топологии сети при распределении процессов.
* **Упаковка данных:** Использование производных типов данных MPI для передачи несмежных участков памяти одним сообщением.

## 4. Какие ограничения возникают при работе с большими данными?

При обработке больших объемов данных (Big Data) в распределенных системах возникают следующие ограничения:

* **Ограничение оперативной памяти (RAM):** Если данные не помещаются в память всех узлов, приходится активно использовать диск (swapping) или перерабатывать алгоритм для блочной обработки (out-of-core), что резко снижает скорость.
* **Пропускная способность сети:** Передача терабайт данных между узлами может стать узким местом ("бутылочным горлышком"), ограничивающим масштабируемость.
* **Скорость ввода-вывода (I/O):** Чтение и запись огромных файлов могут занимать больше времени, чем сами вычисления. Параллельные файловые системы помогают, но имеют свои пределы.
* **Отказоустойчивость:** С увеличением объема данных и времени выполнения растет вероятность сбоя одного из узлов или дисков во время работы.
* **Время инициализации:** Загрузка и распределение больших данных может занимать значительное время перед началом самих вычислений.
