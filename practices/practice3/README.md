# Practice 3: Parallel Sorting on CUDA - Control Questions

## 1. В чем различие между последовательной и параллельной реализациями сортировки слиянием?

**Ответ:**

- **Последовательная (CPU):** Обычно использует рекурсивный подход "сверху-вниз". Сначала массив делится на половины рекурсивно, затем выполняется слияние отсортированных частей.
- **Параллельная (CUDA):** Использует итеративный подход "снизу-вверх".
    1. Массив разбивается на множество небольших блоков, которые сортируются независимо друг от друга множеством блоков потоков (например, используя Bitonic Sort в разделяемой памяти).
    2. Затем выполняется параллельное слияние (Merge) отсортированных последовательностей. На каждом этапе слияния пары блоков объединяются параллельно. В нашей реализации слияние также распараллелено: каждый элемент вычисляет свою позицию в итоговом массиве (Rank-based Merge), что позволяет использовать тысячи потоков одновременно.

## 2. Как распределение потоков и блоков влияет на производительность на CUDA?

**Ответ:**
Эффективное распределение критически важно для **Occupancy** (загруженности GPU):

- Если блоков слишком мало, мультипроцессоры (SM) будут простаивать.
- Если потоков в блоке слишком мало, сложно скрыть задержки доступа к памяти.
- Если потоков слишком много или требуется слишком много регистров/разделяемой памяти, количество активных варпов на SM снижается.
- Распределение должно соответствовать иерархии задачи (Grid -> Block -> Thread) и размерам данных, чтобы максимизировать использование аппаратных ресурсов и пропускной способности памяти.

## 3. Какие сложности возникают при реализации быстрой сортировки (Quick Sort) на GPU?

**Ответ:**

1. **Рекурсия:** GPU имеет ограниченный размер стека. Глубокая рекурсия может вызвать переполнение. Dynamic Parallelism (CDP) позволяет запускать ядра из ядер, но имеет накладные расходы.
2. **Балансировка нагрузки (Load Imbalance):** Выбор опорного элемента (pivot) делит массив на неравные части. Некоторые потоки/блоки могут закончить работу раньше других, вызывая простой.
3. **Branch Divergence:** Потоки в одном варпе могут пойти по разным веткам (меньше pivot или больше), что снижает эффективность выполнения (сериализация варпа).
4. **Синхронизация:** Сложно эффективно организовать слияние или разделение данных между блоками без глобальной синхронизации.

## 4. В каких случаях параллельная реализация сортировки на GPU может быть менее эффективной, чем на CPU?

**Ответ:**

1. **Малые объемы данных:** Накладные расходы на копирование данных (Host-to-Device, Device-to-Host) и запуск ядер превышают выигрыш от параллельных вычислений.
2. **Много последовательных зависимостей:** Например, Heap Sort на фазе извлечения элементов трудно распараллелить эффективно.
3. **Random Access:** Если алгоритм требует хаотичного доступа к памяти (не коалесцированного), пропускная способность падает.
4. **Сложная логика ветвления:** Сильная дивергенция потоков убивает производительность SIMT-архитектуры.

## 5. Почему важно правильно выбирать размер блоков и потоков в CUDA?

**Ответ:**

- **Коалесцированный доступ:** Во многих случаях размер блока, кратный 32 (размер варпа), обеспечивает правильное выравнивание обращений к памяти.
- **Скрытие латентности:** Достаточное количество потоков/варпов позволяет планировщику переключаться на другую работу, пока одни потоки ждут данные из памяти.
- **Ресурсы SM:** Количество регистров и Shared Memory ограничено на SM. Неоптимальный размер блока (например, требующий чуть больше памяти, чем доступно для запуска 2 блоков одновременно) может резко снизить параллелизм (Occupancy cliff).

## 6. Как использование разделяемой памяти (Shared Memory) может повлиять на производительность сортировки?

**Ответ:**

- Разделяемая память работает гораздо быстрее глобальной (аналог управляемого L1-кэша).
- При сортировке (особенно на этапе Bitonic Sort внутри блока) данные загружаются в Shared Memory один раз, сортируются там с высокой скоростью (без обращений к медленной RAM), и выгружаются обратно. Это снижает требования к пропускной способности глобальной памяти и значительно ускоряет выполнение.

## 7. Что означает принцип "разделяй и властвуй" в контексте алгоритмов сортировки?

**Ответ:**
Принцип заключается в рекурсивном разбиении задачи на более простые подзадачи того же типа, их независимом решении и объединении результатов.

- **Merge Sort:** Разделяет массив по индексам (пополам), сортирует части, затем *объединяет* (властвуй).
- **Quick Sort:** Разделяет массив по значению (относительно опорного элемента), сортирует части. "Объединение" происходит тривиально за счет структуры данных.
- Этот принцип идеально подходит для параллелизма, так как подзадачи (после разделения) независимы и могут выполняться одновременно разными ядрами или потоками.
