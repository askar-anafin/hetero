# Контрольные вопросы к Assignment 2

(OpenMP, CUDA и гетерогенные вычисления)

## 1. Что понимается под гетерогенной параллелизацией?

Под гетерогенной параллелизацией понимается использование в одной вычислительной системе различных типов процессорных архитектур (например, CPU и GPU) для совместного выполнения одной задачи. Центральный процессор (CPU) обычно берет на себя управление, логику и последовательные части кода, в то время как графический процессор (GPU) или другие ускорители выполняют массивные параллельные вычисления, для которых они лучше оптимизированы. Это позволяет достичь более высокой производительности и энергоэффективности за счет использования сильных сторон каждой архитектуры.

## 2. В чём принципиальные различия архитектур CPU и GPU?

* **CPU (Central Processing Unit):**
  * Предназначен для минимизации задержек (latency) выполнения одиночных потоков.
  * Имеет небольшое количество мощных ядер.
  * Обладает сложной логикой управления (предсказание ветвлений, внеочередное исполнение).
  * Имеет большие кэши для быстрого доступа к данным.
  * Подходит для сложных последовательных алгоритмов и управления системой.

* **GPU (Graphics Processing Unit):**
  * Предназначен для максимизации пропускной способности (throughput) параллельных вычислений.
  * Имеет тысячи более простых и энергоэффективных ядер.
  * Использует архитектуру SIMD (Single Instruction, Multiple Data) — выполнение одной инструкции над множеством данных.
  * Имеет меньший объем кэша на поток, полагается на быстрое переключение между потоками для скрытия задержек памяти.
  * Идеален для обработки массивов данных, графики и матричных операций.

## 3. Какие типы задач лучше подходят для выполнения на GPU, а какие — на CPU?

* **На GPU:** Задачи с высоким параллелизмом данных (Data Parallelism), где одна и та же операция выполняется над большим количеством элементов независимо друг от друга. Примеры: обработка изображений и видео, обучение нейросетей, матричные вычисления, моделирование физических процессов.
* **На CPU:** Задачи с последовательной логикой, сложными ветвлениями, зависимостями данных, интенсивным вводом-выводом (I/O) и управлением операционной системой. Примеры: компиляция кода, работа с базами данных (частично), веб-серверы, логика бизнес-приложений.

## 4. Почему не все алгоритмы эффективно распараллеливаются с использованием OpenMP?

* **Зависимости по данным:** Если следующая итерация цикла или шаг алгоритма зависит от результата предыдущего, их нельзя выполнить одновременно.
* **Накладные расходы:** Создание и управление потоками требует ресурсов. Для маленьких задач эти расходы могут превышать выигрыш от распараллеливания.
* **Балансировка нагрузки:** Если одни потоки выполняют больше работы, чем другие, общая производительность будет ограничена самым медленным потоком.
* **Ограничение памяти (Memory Bound):** Если алгоритм упирается в пропускную способность памяти, добавление потоков не ускорит вычисления, а может даже замедлить их из-за конкуренции за доступ к памяти.
* **Критические секции:** Частое использование блокировок и атомарных операций вызывает простой потоков в ожидании доступа к ресурсу.

## 5. В чём заключается основная идея алгоритма сортировки слиянием?

Сортировка слиянием (Merge Sort) — это алгоритм типа "разделяй и властвуй". Его идея заключается в следующем:

1. **Разделение:** Исходный массив рекурсивно разбивается на две половины, пока не останутся подмассивы из одного элемента (которые считаются отсортированными).
2. **Слияние:** Соседние подмассивы сливаются (объединяются) обратно в один общий массив, при этом элементы упорядочиваются в процессе слияния.
Этот процесс продолжается снизу вверх, пока не будет получен полностью отсортированный массив.

## 6. Какие сложности возникают при реализации сортировки слиянием на GPU?

* **Сложность рекурсии:** GPU плохо приспособлены для глубокой рекурсии из-за ограниченного стека. Обычно алгоритм переписывают в итеративном виде.
* **Доступ к памяти:** На этапе слияния важно обеспечить коалесцированный (упорядоченный) доступ глобальной памяти для максимальной скорости. Хаотичные обращения к памяти сильно снижают производительность.
* **Синхронизация:** Необходимо синхронизировать работу тысяч потоков. Слияние требует обмена данными между потоками и блоками, что требует использования барьеров и разделяемой памяти.
* **Управление памятью:** Требуется дополнительная память для буфера слияния, что увеличивает потребление ресурсов GPU.

## 7. Как выбор размера блока и сетки влияет на производительность вычислений на GPU?

* **Размер блока (Block Size):**
  * Слишком маленький размер может не позволить полностью загрузить вычислительные блоки (SM) и скрыть задержки обращения к памяти.
  * Слишком большой размер может исчерпать доступные регистры или разделяемую память (Shared Memory), что снизит количество активных блоков (Occupancy).
  * Обычно выбирают размеры кратные 32 (размер варпа), например 128, 256 или 512 потоков.
* **Размер сетки (Grid Size):** Должен быть достаточным, чтобы загрузить работой все доступные мультипроцессоры GPU.

Правильный выбор параметров позволяет максимизировать загруженность GPU (Occupancy) и эффективность вычислений.

## 8. Почему гетерогенный подход может быть эффективнее использования только CPU или только GPU?

Гетерогенный подход позволяет устранить "узкие места", свойственные каждой архитектуре по отдельности. Перенося "тяжелые", но хорошо распараллеливаемые задачи на GPU, мы освобождаем CPU для быстрой реакции на события, управления и выполнения сложной последовательной логики. Это позволяет достичь баланса, при котором каждый компонент системы выполняет ту работу, для которой он был спроектирован, что приводит к максимальной общей производительности системы (закон Амдала для гетерогенных систем) и часто к лучшей энергоэффективности.
