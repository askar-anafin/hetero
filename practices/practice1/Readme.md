# Контрольные вопросы

1. **В чём основные отличия между массивами и динамическими структурами данных?**
   - **Массивы** имеют фиксированный размер, определенный при создании (статические массивы) или выделении (динамические массивы, хотя `std::vector` может менять размер, под капотом это перевыделение массива). Элементы располагаются в памяти последовательно, что обеспечивает быстрый доступ по индексу (сложность O(1)) и хорошую работу с кэшем процессора.
   - **Динамические структуры данных** (например, связанные списки, деревья, графы) могут гибко изменять свой размер и структуру во время выполнения программы. Элементы часто располагаются в разных областях памяти и связаны указателями. Вставка и удаление элементов могут быть более эффективными (O(1) при наличии указателя), но доступ к произвольному элементу обычно требует перебора (O(n)).

2. **Что такое указатель, и как он используется в языке C++?**
   - **Указатель** — это переменная, значением которой является адрес ячейки памяти.
   - **Использование в C++:**
     - Динамическое выделение памяти (оператор `new`).
     - Работа с массивами и адресная арифметика.
     - Передача аргументов в функции по адресу (позволяет изменять оригинальные переменные и избегать копирования больших объектов).
     - Построение сложных структур данных (списки, деревья).
     - Полиморфизм (указатели на базовый класс).

3. **Объясните принцип работы стека и очереди.**
   - **Стек (Stack):** Работает по принципу **LIFO** (Last In, First Out — "последним пришел, первым ушел"). Основные операции: `push` (добавить на вершину) и `pop` (удалить с вершины). Пример: стопка тарелок.
   - **Очередь (Queue):** Работает по принципу **FIFO** (First In, First Out — "первым пришел, первым ушел"). Элементы добавляются в конец (`enqueue` / `push`), а извлекаются из начала (`dequeue` / `pop`). Пример: очередь в магазине.

4. **Каковы преимущества и недостатки односвязных списков по сравнению с массивами?**
   - **Преимущества:**
     - Эффективное использование памяти при неизвестном заранее количестве элементов (выделяется ровно столько, сколько нужно).
     - Быстрая вставка и удаление элементов в начало или середину списка (O(1)), если известен указатель на место вставки, так как не нужно сдвигать остальные элементы (как в массиве).
   - **Недостатки:**
     - Медленный доступ к произвольному элементу (O(n)), так как нужно проходить по указателям от начала.
     - Дополнительные расходы памяти на хранение указателя для каждого элемента.
     - Худшая локальность данных (разброс по памяти), что снижает эффективность кэширования.

5. **Как правильно освобождать память в языке C++ после работы с динамическими структурами?**
   - Если память была выделена с помощью `new` (для одиночного объекта), она должна быть освобождена с помощью `delete`.
   - Если память была выделена с помощью `new[]` (для массива), она должна быть освобождена с помощью `delete[]`.
   - Важно избегать **утечек памяти** (memory leaks), освобождая все выделенные ресурсы, и **висячих указателей** (dangling pointers), обнуляя указатели после `delete` (`ptr = nullptr;`).
   - Использование **умных указателей** (`std::unique_ptr`, `std::shared_ptr`) автоматизирует этот процесс по принципу RAII.

6. **Почему важно понимать работу с указателями и динамической памятью для параллельного программирования?**
   - В параллельных средах (OpenMP, CUDA, MPI) управление памятью становится критичным.
   - Ошибки с указателями могут привести к **состоянию гонки** (race conditions), когда несколько потоков некорректно обращаются к одной области памяти.
   - Неправильное разыменование указателей может вызвать сегментационные ошибки (segfault) в непредсказуемые моменты.
   - Понимание того, где находятся данные (в стеке потока или в общей куче), важно для предотвращения конфликтов и оптимизации производительности (false sharing).

7. **Как использовать reduction в OpenMP для нахождения суммы, минимума или максимума в массиве?**
   - Клауза `reduction` позволяет безопасно выполнять агрегационные операции над общей переменной без явного использования мьютексов или атомиков. OpenMP создает локальные копии переменной для каждого потока, а в конце объединяет их.
   - **Сумма:** `#pragma omp parallel for reduction(+:сумма)`
   - **Минимум:** `#pragma omp parallel for reduction(min:минимум)`
   - **Максимум:** `#pragma omp parallel for reduction(max:максимум)`

8. **Как влияет параллельное программирование на производительность при работе с большими массивами?**
   - **Ускорение:** Параллельная обработка позволяет задействовать несколько ядер CPU, теоретически уменьшая время выполнения пропорционально числу ядер (закон Амдала накладывает ограничения).
   - **Эффективность:** Для больших массивов накладные расходы на создание потоков становятся ничтожными по сравнению с объемом вычислений.
   - **Ограничения:** Если алгоритм ограничен пропускной способностью памяти (memory bound), увеличение числа потоков может не дать прироста или даже замедлить работу из-за конкуренции за шину памяти. Также важна балансировка нагрузки.
