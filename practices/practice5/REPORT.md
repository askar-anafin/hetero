# Отчет по Практической Работе №5: Параллельные структуры данных (Stack и Queue) на CUDA

## 1. Введение

Целью работы являлось изучение принципов построения параллельных структур данных на GPU. Были реализованы параллельные Стек (Stack) и Очередь (Queue) с использованием технологии CUDA, проведено сравнение их производительности с последовательными версиями на CPU, а также исследованы методы оптимизации с применением разделяемой памяти (Shared Memory) и кольцевых буферов.

## 2. Реализация Задач

В ходе работы были разработаны следующие компоненты (в файлах `stack_queue.cu` и `stack_queue_opt.cu`):

### Задание 1: Параллельный Стек (Global Memory)

* **Структура:** Использует выделенный массив в глобальной памяти и один указатель вершины `top`.
* **Push (Вставка):** Потоки используют `atomicAdd(top, 1)` для получения уникального индекса и записи значения.
* **Pop (Удаление):** Потоки используют `atomicSub(top, 1)` для декремента вершины и чтения значения.

### Задание 2: Параллельная Очередь (Global Memory)

* **Структура:** Использует два указателя: `head` (начало) и `tail` (конец).
* **Enqueue:** Атомарное увеличение `tail` (`atomicAdd`) резервирует место для новой записи.
* **Dequeue:** Атомарное увеличение `head` резервирует элемент для чтения.

### Задание 3: Оптимизации и MPMC

* **MPMC Queue (Multi-Producer Multi-Consumer):** Реализована более устойчивая версия очереди. Используется принцип кольцевого буфера (Circular Buffer) с модульной арифметикой (`index % capacity`). Это позволяет переиспользовать освободившиеся ячейки памяти и работать с потоками данных, превышающими физический размер массива.
* **Shared Memory Stack:** Реализована демонстрация использования быстрой разделяемой памяти (Shared Memory) внутри блока. Это позволяет группе потоков работать с локальным стеком, существенно снижая нагрузку на медленную глобальную память (Global Memory) и уменьшая количество конфликтов (contention) атомарных операций.

## 3. Принцип работы и Механизмы

1. **Атомарные операции:** Ключевым элементом параллелизма являются инструкции `atomicAdd`, `atomicSub` и `atomicCAS`. Они гарантируют целостность данных при конкурентном доступе тысяч потоков, но приводят к сериализации запросов к одной ячейке памяти.
2. **Состояние гонки (Race Conditions):** Без атомарных операций несколько потоков могли бы прочитать одно и то же значение индекса, что привело бы к перезаписи данных. Использование атомиков решает эту проблему.
3. **Кольцевой буфер (в MPMC):** Решает проблему "убегающих" индексов в базовой очереди, где `head` и `tail` только растут.

## 4. Инструментарий и Измерения

Для автоматизации сборки и анализа результатов были созданы вспомогательные скрипты:

* **`run.bat`**: Скрипт для компиляции программ с помощью компилятора `nvcc` и их последовательного запуска.
* **`plot_results.py`**: Python-скрипт для визуализации данных. Он перехватывает вывод программы, парсит время выполнения операций (в миллисекундах) и строит сравнительные гистограммы в файле `comparison_results.png`.

## 5. Заключение

Работа продемонстрировала фундаментальные отличия в проектировании структур данных для GPU. Параллельная реализация требует явного управления синхронизацией. Простые алгоритмы с глобальной памятью страдают от высокой латентности атомарных операций. Применение оптимизаций, таких как Shared Memory и алгоритмы без блокировок (lock-free) с кольцевыми буферами, позволяет значительно повысить пропускную способность параллельных структур данных.
