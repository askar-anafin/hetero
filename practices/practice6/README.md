# Практическая работа 6: Введение в OpenCL

## Контрольные вопросы

### 1. Какие основные типы памяти используются в OpenCL?

OpenCL имеет иерархическую модель памяти, состоящую из четырех основных типов, каждая из которых имеет свою область видимости и скорость доступа:

* **Global Memory (Глобальная память):** Доступна всем work-items (потокам) во всех рабочих группах. Самая большая по объему, но самая медленная (аналог RAM видеокарты). Данные передаются сюда с хоста (CPU). Ключевое слово: `__global`.
* **Constant Memory (Константная память):** Область глобальной памяти, доступная только для чтения. Она кэшируется на устройстве, что делает доступ к ней быстрее, чем к обычной глобальной памяти, если все потоки читают одни и те же адреса. Ключевое слово: `__constant`.
* **Local Memory (Локальная память):** Доступна только work-items внутри одной рабочей группы. Она намного быстрее глобальной памяти (аналог L1/Shared memory) и используется для обмена данными между потоками одной группы. Ключевое слово: `__local`.
* **Private Memory (Частная память):** Приватная для каждого отдельного work-item (потока). Сюда попадают регистры и переменные стека. Самая быстрая, но очень ограниченная по объему. Используется для локальных переменных ядра. Ключевое слово: `__private` (или по умолчанию).

### 2. Как настроить глобальную и локальную рабочую группу?

В OpenCL конфигурация рабочих групп задается при вызове ядра через функцию `clEnqueueNDRangeKernel` с помощью двух аргументов:

* **global_work_size (Глобальный размер):** Общее количество work-items (потоков), которые будут запущены. Это массив, определяющий размерность задачи (1D, 2D или 3D). Например, для обработки массива из $N$ элементов, global size будет равен $N$.
* **local_work_size (Локальный размер):** Количество work-items в одной рабочей группе (work-group). Все потоки группы выполняются на одном Compute Unit и могут использовать общую локальную память.
  * Если установить `local_work_size` в `NULL`, драйвер OpenCL сам выберет оптимальный размер.
  * Если задавать вручную, размер должен быть делителем глобального размера (например, Global=1024, Local=256 -> 4 группы).

Пример кода C++:

```cpp
size_t globalSize = 1024;
size_t localSize = 256; 
clEnqueueNDRangeKernel(queue, kernel, 1, 
                       NULL, 
                       &globalSize, // Всего 1024 потока
                       &localSize,  // По 256 потоков в группе
                       0, NULL, NULL);
```

### 3. Чем отличается OpenCL от CUDA?

* **Платформонезависимость:**
  * **OpenCL (Open Computing Language):** Открытый стандарт, поддерживаемый множеством вендоров. Работает на CPU (Intel, AMD), GPU (NVIDIA, AMD, Intel), FPGA и DSP. Один и тот же код может работать на разном оборудовании.
  * **CUDA (Compute Unified Device Architecture):** Проприетарная технология NVIDIA. Работает **только** на графических процессорах NVIDIA.
* **Экосистема и сложность:**
  * **CUDA:** Имеет более развитую экосистему библиотек (cuBLAS, cuDNN), более простой синтаксис (расширение C++) и зрелые инструменты отладки. Обычно обеспечивает более высокую производительность на картах NVIDIA "из коробки".
  * **OpenCL:** Требует написания большего количества шаблонного кода ("boilerplate") для инициализации (платформы, устройства, контексты). Сложнее в освоении, но дает гибкость выбора железа.
* **Компиляция:**
  * **CUDA:** Компилируется заранее (AOT) или в PTX, тесная интеграция с хост-кодом (Single-Source).
  * **OpenCL:** Часто использует JIT-компиляцию ядра из исходного кода прямо во время выполнения программы (через `clCreateProgramWithSource`).

### 4. Какие преимущества дает использование OpenCL?

1. **Гетерогенность:** Способность использовать все вычислительные ресурсы системы одновременно. Можно распределять задачи между CPU, встроенной графикой и дискретной видеокартой.
2. **Переносимость (Portability):** Написанная программа будет работать практически на любой современной видеокарте или процессоре, независимо от производителя (AMD, NVIDIA, Intel, ARM). Это избавляет от привязки к одному вендору (Vendor Lock-in).
3. **Гибкость:** Возможность выполнять вычисления на устройствах, не являющихся видеокартами, например, на FPGA для специализированных задач с низкой задержкой.
4. **Открытый стандарт:** Бесплатное использование, спецификация развивается консорциумом Khronos Group.
