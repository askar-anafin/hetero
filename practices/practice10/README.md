# Практическая работа 10. Ответы на контрольные вопросы

## 1. В чём отличие измерения времени выполнения от профилирования?

**Измерение времени выполнения** (benchmarking) — это процесс определения общего времени, затраченного программой или её отдельными частями на выполнение задачи. Оно дает макроскопическую оценку производительности: «сколько времени занял расчет?».

**Профилирование** (profiling) — это детальный анализ того, **как** используются ресурсы системы во время выполнения программы. Профилировщики показывают:

* В каких функциях или строках кода программа проводит больше всего времени (Hotspots).
* Количество вызовов функций.
* Использование памяти, кэш-промахи, ветвления.
* Утилизацию GPU/CPU.

**Кратко:** Измерение времени отвечает на вопрос «Как долго?», а профилирование — «Почему так долго и где именно?».

## 2. Какие виды узких мест характерны для CPU, GPU и распределённых программ?

* **CPU:**
  * **Зависимости по данным:** Невозможность выполнить инструкции параллельно из-за ожидания результатов предыдущих операций.
  * **Кэш-промахи (Cache misses):** Частые обращения к медленной оперативной памяти вместо быстрого кэша.
  * **Ошибки предсказания ветвлений (Branch mispredictions):** Сброс конвейера при неверном угадывании пути исполнения `if/else`.
* **GPU:**
  * **Пропускная способность памяти (Memory Bandwidth Bound):** Ядра простаивают, ожидая данные из глобальной памяти.
  * **Дивергенция потоков (Warp Divergence):** Потоки в одном варпе идут по разным веткам ветвления, что заставляет выполнять ветки последовательно.
  * **Низкая занятость (Occupancy):** Недостаточное количество активных варпов, чтобы скрыть латентность памяти.
* **Распределённые программы (Кластеры/MPI):**
  * **Сетевая латентность и пропускная способность:** Время передачи сообщений между узлами.
  * **Синхронизация:** Ожидание самого медленного узла (load imbalance).
  * **Накладные расходы на коммуникацию:** Когда время передачи данных превышает время вычислений.

## 3. Почему увеличение числа потоков или процессов не всегда приводит к ускорению?

* **Закон Амдала:** Существует последовательная часть программы, которую нельзя распараллелить. При бесконечном числе потоков ускорение упрется в эту часть.
* **Накладные расходы (Overhead):**
  * Создание и уничтожение потоков.
  * Переключение контекста.
  * Синхронизация (захват/освобождение мьютексов, барьеры).
* **Конкуренция за ресурсы (Resource Contention):**
  * Потоки могут бороться за доступ к одной линии кэша (False Sharing).
  * Насыщение пропускной способности шины памяти.
* **Недостаток работы:** Если задача слишком мала, время на управление потоками превысит выигрыш от параллелизма.

## 4. Как законы Амдала и Густафсона применяются при анализе масштабируемости?

* **Закон Амдала (Strong Scaling):** Оценивает ускорение при **фиксированном размере задачи** и увеличении числа процессоров.
  * Показывает теоретический предел ускорения.
  * Используется для понимания, имеет ли смысл добавлять ресурсы для решения *той же самой* задачи быстрее.
  * Формула: $S = \frac{1}{(1-P) + \frac{P}{N}}$, где $P$ — параллельная доля.
* **Закон Густафсона (Weak Scaling):** Оценивает ускорение, если при увеличении числа процессоров **пропорционально увеличивается размер задачи**.
  * Предполагает, что время выполнения должно оставаться постоянным.
  * Показывает, что массивные параллельные системы эффективны для *больших* задач, которые не влезают в один процессор.
  * Используется для оценки масштабируемости алгоритма на большие объемы данных.
  * Формула: $S = N - (1-P)(N-1)$.

## 5. Какие факторы наиболее критичны для производительности гибридных приложений?

Гибридные приложения используют сочетание разных архитектур (например, CPU + GPU или CPU + FPGA).

* **Обмен данными (Data Transfer):** Передача данных по шине (например, PCIe) является самым узким местом. Необходимо минимизировать копирования (Host-to-Device и обратно) и использовать асинхронные передачи.
* **Балансировка нагрузки (Load Balancing):** Правильное распределение работы между CPU и ускорителем. GPU хорош для массивного параллелизма, CPU — для сложной логики и ветвлений.
* **Накладные расходы на запуск ядер (Kernel Launch Overhead):** Запуск задач на ускорителе требует времени. Слишком мелкие ядра могут выполняться дольше, чем подготовка к их запуску.
* **Синхронизация:** Эффективное ожидание завершения работы ускорителя без блокировки CPU (использование потоков/стримов).
